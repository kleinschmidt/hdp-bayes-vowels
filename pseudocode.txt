LEX HDP PSEUDOCODE

Data structures:
    words: 
        each word is a list (tuple) of ndarrys + label
    lexicon:
        dict mapping label --> lexeme
	lexeme:
	    list of (n, mean, var, phon label)
    phons:
        dict mapping label --> phon
	phon:
	    list of (n, mean, var)

lexdp:
	words
	lexs
	phondp
	iterate():
		perform one sweep through the words
		for word, lex in words:
		    	  lex.holdout(word)
			  Ls = [l.lhood(word) for l in lexs+self.sample_prior(r)]
			  
	sample():
		return a random lex (according to DP)
	sample_prior():
		return a random lex (according to prior defined by phondp)

words:
	list( (word_1, lex_z1), (word_2, lex_z2), ..., (word_n, lex_zn) )

word:
	list(obs_1, obs_2, ..., obs_i)

lexs:
	list( lex_1, lex_2, ..., lex_m )

lex: 
	list( (obs_1, phon_1), (obs_2, phon_2), ..., (obs_i, phon_i) )
	count (number of words this lex is responsible for)
	add(word):
		update stats segment-wise
		update parent phon's stats
	remove(word)
		update stats segment-wise
		update parent phon's stats
	lhood(word)
		L = 0
		for each segment s_i:
		    	 L += phon_i.lhood(s_i)

phondp:
	lexs (analogous to words in lexdp--patrons)
	phons (analogous to lexs in lexdp--tables)
	params
	newphon()
	iterate():
		perform one sweep through lexs
	sample():
		return a random phon (according to DP)

phon:
	obs (RunningVar instance)
	count (number of segments this phon is responsible for)
	add(seg)
	remove(seg)
	lhood(seg)
	

running_var:
	n, m, s
	push(x)
	pull(x)
	merge(rv2)
	split(rv2)
	
	
  
Word sweep:
    for word W in words:
        hold out W:
	    decrement N_k (k=z_W)
	    decrement component stats
       for lexeme L in lexicon:
	    compute likelihood of W given L:
	        for each segment S of W:
		    eval likelihood function for each phon cat
		multiply likelihoods
	compute prior likelihood of W:
	    sample r lexemes from phonemes
	    compute likelihood of W for each new lexeme
	adjust likelihoods according to counts
	sample Z_new
	if Z_new is new:
	    (bookkeeping)
	Bookkeeping:
	    write Z_new to Zs
	    increment Z_new stats according to W
	    
    

Phone sweep
    for lexeme L in lexicon:
        for each segment S in L:
	    hold out S
	    for each phon P:
	    	compute lhood of S given P
	    compute prior of S
	    sample Z_new given lhoods/prior
	    assign S to Z_new



--------NOTES ------------------------------------------
can just keep track of category summary statistics?
  e.g. keep track of mean, variance, n for each lexical phoneme category
  update
  --> YES WE CAN -- Knuth's algorith for running mean/variance

so only need to keep forward labels: word/segment labels
and update incrementally/decrementally the category parameters
  (both for word categories and phoneme categories)

categories are defined by:
  summary stats:
    mean
    count
    variance
  parent category (e.g. segment labels for lexemes)
(for lexical categories mean/variances are vectors -- one per segment)
